%作者：汪斐然
%模板用途：模式识别报告
%时间：2021年3月

%这是一份基于《2020-2021模式识别期末提交模板》Word版制作的Latex模板。用于方昱春老师的模式识别课程报告。
%文档中对Latex的各种使用方式都准备了样例并进行备注，包括标题设置、图表添加、文献引用以及字体设置等。
%参考文献格式和Word版存在一定的区别，使用的是IEEETR格式。是IEEE期刊使用的参考文献引用标准。
%参考文献选择使用IEEETR格式的原因在于，可以在文章中对参考文献进行超链接索引。
%希望这份模板可以帮助同学们快速上手Latex，制作漂亮的课程报告；可以在同学们之后的研究学习过程中成为学术论文的参考模板。

%Latex工具：本地编辑平台：TexWorks；在线编辑平台：Overleaf（推荐）

%Latex快速入门教程：
%1、https://muyuuuu.github.io/2018/11/07/Brief-introduction-to-LaTex/
%2、https://liam.page/2014/09/08/latex-introduction/

%Latex快速辅助工具使用说明：
%快速绘制表格工具：https://www.tablesgenerator.com/
%快速生成公式工具：https://mathpix.com/

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%环境配置%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage[UTF8]{ctex}
\usepackage[left=3.18cm,right=3.18cm,top=2.54cm,bottom=2.54cm]{geometry}
\geometry{a4paper}

%附录包
\usepackage{appendix} 
\usepackage{listings}

%代码格式
\usepackage{xcolor}
\lstset{
    numbers=left, 
    numberstyle= \tiny, 
    keywordstyle= \color{ blue!70},
    commentstyle= \color{red!50!green!50!blue!50}, 
    frame=shadowbox, % 阴影效果
    rulesepcolor= \color{ red!20!green!20!blue!20} ,
    escapeinside=``, % 英文分号中可写入中文
    xleftmargin=2em,xrightmargin=2em, aboveskip=1em,
    framexleftmargin=2em
} 
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the 
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the 

%数学
\usepackage{amsmath}
\usepackage{amsthm}

%图片
\usepackage{graphicx} %添加图片

%字体、格式设置
\usepackage{subfigure}
\usepackage{float}
\usepackage{xeCJK}
\renewcommand{\vec}[1]{\boldsymbol{#1}} % 生产粗体向量，而不是带箭头的向量
\usepackage{amssymb}
\usepackage{booktabs} % excel导出的大表格
\usepackage{hyperref}
\usepackage{titlesec}%设置字体的包
\usepackage{multirow}
%可选字体：
% \noindent 中文字体（默认宋体）\\
% \fangsong 中文字体（仿宋） \songti 中文字体（宋体） \lishu 中文字体（隶书） \heiti 中文字体（黑体）\\
% \CJKfamily{zhkai} 中文字体（楷书） \CJKfamily{zhyou} 中文字体（幼圆） \CJKfamily{zhyahei} 中文字体（微软雅黑）\\

%调整图表标题的字体样式
\usepackage{caption}
\captionsetup{font={small,bf}} 

%新定义
\newtheorem{definition}{定义} %中文
\newtheorem{lemma}{引理}
\newtheorem{theorem}{定理}
\DeclareMathOperator{\Ima}{Im}%定义新符号
\DeclareMathOperator{\Rank}{rank}%定义求秩算子



%设置标题，作者
\title{\textbf{基于HOG+SVM与YOLO的路标识别分类}}
\author{
郑力铖(21122873)
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%正文%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\songti（宋体）设置全文字体，可改为\heiti（黑体），\fangsong（仿宋）
\begin{document} \songti

% 插入封面
\include{cover} %调用封面文件

\date{}
\maketitle


%%%%%%%%%%%%%%%%%%%%%%摘要%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%由摘要和关键词两部分组成
\begin{center}
    \setlength{\textwidth}{15cm}
    \parbox{\textwidth}{
        \textbf{摘要：}作为交通系统的基本要素，交通标志提供了关于驾驶员、行人等的道路状况的重要信息，来降低事故风险。随着计算机视觉和人工智能的快速发展，交通标志识别算法已被应用于先进的驾驶员辅助系统和自动驾驶系统，以帮助驾驶员和自动驾驶车辆准确获取道路信息。然而在实际应用中，交通标志识别仍然具有挑战性。本文对比了经典的机器学习方法HOG+SVM，和通用视觉识别模型yolov5和yolov8方法，探讨在自动驾驶场景下的路标识别方法。
        \newline
        \textbf{关键词：}图像识别, 支持向量机, 深度学习, 神经网络。
    }
\end{center}

%%%%%%%%%%%%%%%%%%%%%%目录%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
% \tableofcontents
% \newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%一级标题
\section{引言}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%二级标题
\subsection{问题提出}
%三级标题
作为高级驾驶员辅助系统（ADAS）和自动驾驶系统（ADS）的重要组成部分，交通标志识别（TSR）技术可以帮助驾驶员和自动驾驶汽车获取重要的道路信息\cite{chen2022realtime}。交通标志识别TSR是一种为自动驾驶车辆识别道路上的交通标志的智能识别系统，是物体检测的一个子任务，类似于人脸识别。

TSR系统通常由检测和分类两个阶段组成。检测通常使用形状和颜色来识别交通标志的特征，从而从自然场景中提取交通标志。更好的分类能更准确地识别的内容检测到的交通信号。交通标志的识别度，对于避免道路事故具有重大意义\cite{Zhang2017}。本文通过对比不同方法的实际应用效果，旨在为自动驾驶系统选择最合适的路标识别方法提供参考。考虑到实时性、准确性和鲁棒性等因素，读者将能够更好地了解何种方法在特定条件下更为适用。

%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{求解方案分析}
一般来说，交通标志识别有两种检测方法，一种是传统方法（人工定制的特征），另一种是深度学习方法（学习具有深度神经网络的特征）。对于传统方法而言，整个实现流程通常包括的提取区域兴趣（包括交通标志），提取特征（例如HOG），以及然后将这些特征发送到分类器（例如SVM）。然而，传统方法在多类任务中的表现的性能较差。近年来，深度学习方法在许多任务中表现出优异的性能，例如图像分类和检测。对于对象检测，深度学习方法（例如YOLO\cite{ref9}，Faster R-CNN\cite{Ren2016}）在主流基准上表现良好，准确度和速度都较传统方法有较大优势。

早在 2005 年，方向梯度直方图（HOG）就被提出，HOG用来提取图片特征，并和支持向量机（SVM）结合，最早用来进行行人检测。HOG+SVM这种经典的机器学习方法在过去取得了一定的成功，但随着技术的进步，人们开始寻求更加高效、准确的解决方案。

近年来，YOLO算法以其高速度和高精度迅速走红。因此，本文深入研究了YOLOv5和YOLOv8这两种先进的目标检测模型。这两种模型都是基于YOLO模型的优化，利用深度学习技术，通过神经网络层次结构和先进的目标检测算法，在图像中快速准确地识别路标。相较于传统方法，它们在处理复杂场景和多类别标识时表现更为出色。

%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{论文概述}
本文的其余部分的组织如下。在第二章我们介绍了梯度直方图与支持向量机（HOG+SVM），以及对象检测算法YOLO的算法概述。在第三章我们实现了HOG+SVM，YOLOv5和YOLOv8在数据集上的实验代码，介绍了算法的总体框架，并做了一部分改进。第四章分别对HOG+SVM，和YOLO的两种算法进行了对比，同时在YOLOv5和YOLOv8间的实验结果做了对比。最后在第五章做了讨论和结论。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{相关算法概述}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{梯度直方图（HOG）}
梯度直方图（Histogram of oriented gradient，简称HOG）\cite{1467360}是应用在计算机视觉和图像处理领域，用于目标检测的特征描述器。这项技术是用来计算局部图像梯度的方向讯息的统计值。在HOG特征描述符中，梯度方向的分布，也就是梯度方向的直方图被视作特征。图像的梯度(x和y导数)非常有用，因为边缘和拐角(强度突变的区域)周围的梯度幅度很大，并且边缘和拐角比平坦区域包含更多关于物体形状的信息。方向梯度直方图(HOG)特征描述符常和线性支持向量机(SVM)配合使用，用于训练高精度的目标分类器。

\subsection{支持向量机（SVM）}
支持向量机（Support Vector Machine，常简称为SVM，又名支持向量网络）\cite{708428}是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。

\subsection{对象检测算法YOLO}
YOLO（You Only Look Once）\cite{ref9}是一种流行的对象检测和图像分割模型，由华盛顿大学的Joseph Redmon和Ali Farhadi开发。它的主要特点是在一次前向传递中，同时完成对象定位和分类。相较于传统的对象检测方法，YOLO在速度和准确性上取得了很大的突破。这使得它适用于实时目标检测任务，如视频分析和自动驾驶。

YOLOv5已是目前最广泛使用的YOLO网络。相较于其前身有一系列改进，包括使用更强大的骨干网络、添加了超参数优化、采用自适应训练策略以适应不同数据集，以及支持多尺度训练，提高对小目标的检测能力等。并集成实验跟踪和自动导出到流行导出格式等工程上的新功能。YOLOv8是Ultralytics的YOLO的最新版本。作为目前最尖端、最先进的YOLO版本，YOLOv8在先前版本的成功基础上，引入了新功能和改进，以增强性能、灵活性和效率。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{算法实现描述}
\subsection{HOG+SVM实现}
\begin{algorithm}[H]
    \caption{ HOG+SVM路标识别算法步骤}
    \begin{algorithmic}[1]
        \Require
        训练数据集；
        待预测数据；
        \Ensure
        预测数据的类别，与兴趣区域位置;
        \State 加载数据;
        \State 图片预处理：二值化，开闭运算;
        \State 边缘检测提取候选区域;
        \State 在候选区域中提取HOG特征图;
        \State 用SVM分类器判别HOG特征图。
        \Return
        候选区域框位置，SVM类别预测值;
    \end{algorithmic}
\end{algorithm}


\subsection{YOLO实现}

\begin{algorithm}[H]
    \caption{ YOLO路标识别算法步骤}
    \begin{algorithmic}[1]
        \Require
        训练数据集；
        待预测数据；
        \Ensure
        预测数据的类别，与兴趣区域位置;
        \State 加载数据;
        \State YOLO网络预测;
        \Return
        候选区域框位置，类别预测值;
    \end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{实验描述}
\subsection{实验数据和实验方案}
实验所使用的数据集来自于\href{https://www.kaggle.com/}{\textbf{kaggle.com}}中的\href{https://www.kaggle.com/datasets/pkdarabi/road-mark-detection}{\textbf{road-mark-detection}}数据集，该数据集已划分好训练集、验证集和测试集，并且已经缩放到640*640的图片大小。共含训练集2167张，验证集417张，测试集192张。

首先，考虑到机器学习算法对于多分类任务的短板，我们选取1200张已标注的训练数据上，仅选取6种路标训练HOG特征，并由SVM进行分类，计算每种类别的精确率、召回率和F1得分。分析该方法的性能。

在这之后，我们部署YOLOv5和YOLOv8，v5作为目前最广泛使用的YOLO引擎，对比v8作为目前的最优算法SOTA。在mAP、精确率、召回率和F1得分上作对比，比较两者性能。且与HOG+SVM的实验结果做对比，并分析原因。

\subsection{实验的评价指标}
本文主要使用精确率（Precision）、召回率（Recall）、F1分数（F1 score）和平均精度均值（mAP）对模型进行评价。

精确率是指模型预测为正类别的样本中，实际为正类别的比例。召回率是指实际为正类别的样本中，模型成功预测为正类别的比例。F1分数是精确率和召回率的调和平均，它综合考虑了两者之间的平衡。其三者的计算公式为：
   \[ \text{Precision} = \frac{\text{TP}}{\text{TP + FP}} \]
   \[ \text{Recall} = \frac{\text{TP}}{\text{TP + FN}} \]
   \[ \text{F1 score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision + Recall}} \]

mAP主要用于评估目标检测任务中的性能。它是所有类别的平均精度（AP）的平均值。每个类别的AP是计算Precision-Recall曲线下的面积。mAP提供了对模型在多类别场景中的整体性能的综合评估。
数学上，mAP的计算公式可以表示为：
\[ mAP = \frac{1}{n} \sum_{i=1}^{n} AP_i \]

其中，\( n \) 是类别的总数，\( AP_i \) 是第 \( i \) 个类别的 Average Precision。

\subsection{HOG+SVM实验及结果分析}
在针对1200张图片学习针对的6种路标后，HOG+SVM算法的精确率、召回率和F1得分如表1所示。因其得分相当不可看，因此也无法进行合适的绘图。这样结果的原因，很大程度上是由于SVM算法无法胜任针对多分类的复杂现实问题。
\begin{table}[H]
    \caption{HOG+SVM的路标识别多指标分析}
    \begin{center}\label{table:score}
        % \begin{tabularx}{\linewidth}{|c|X|X|X|}
        \begin{tabular}{|c|r|r|r|}
            \hline
                 & \multicolumn{1}{c|}{精确率} & \multicolumn{1}{c|}{召回率} & \multicolumn{1}{c|}{F1得分} \\ \hline
            直行标志 & \quad0.3706\quad\quad& \quad0.3251\quad\quad& \quad0.3464\quad\quad\\ \hline
            左转标志 & \quad0.5889\quad\quad& \quad0.3869\quad\quad& \quad0.4670\quad\quad\\ \hline
            右转标志 & \quad0.3750\quad\quad& \quad0.4565\quad\quad& \quad0.4118\quad\quad\\ \hline
            禁止鸣笛 & \quad0.4999\quad\quad& \quad0.5682\quad\quad& \quad0.5319\quad\quad\\ \hline
            人行横道 & \quad0.8095\quad\quad& \quad0.5965\quad\quad& \quad0.6869\quad\quad\\ \hline
            禁止通行 & \quad0.7288\quad\quad& \quad0.7049\quad\quad& \quad0.7167\quad\quad\\ \hline
        \end{tabular}
    \end{center}
\end{table}

如图1所示，虽然在背景是阴天的情况下，在空中的车道指示路标可以非常好的被识别出，但在一般情况下，如图2中的高架桥下的真实情况所示，图片左上角的右转路标的roi明显较小，且将摩托车错检为了人行横道标识，并且这样错检的情况在测试中相当普遍，这导致了该方法在指标上的落后，现实场景下也难以应用。
\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=1\linewidth, trim=0 50 0 50, clip]{test_results/sign_433_result.jpg}
        \caption{质量较好的HOG+SVM检测结果}
        \label{fig:1}
    \end{minipage}
    \begin{minipage}[t]{0.49\linewidth}
        \centering
        \includegraphics[width=1\linewidth, trim=50 30 50 160, clip]{test_results/sign_120_result.jpg}
        \caption{明显错检与roi不一致问题}
        \label{fig:2}
    \end{minipage}
 \end{figure}

\subsection{YOLOv5与v8实验及结果分析}

在经过4.2节实验，验证了HOG+SVM算法在现实场景中的局限性后，我们部署当下最流行的通用检测模型YOLOv5，和YOLO的最新SOTA YOLOv8。实验时我们自己设计了一个绘制准确度-召回率图的代码，因v5与v8两者的PR曲线差距不大，本文即以v5为例。

如图3，YOLOv5达成了所有分类mAP@0.5值为0.908的高输出。黄车道线Liniya2由于与白车道线Liniya1相似，且数据量较少，容易产生错检，未能非常好的识别。而其他类别有非常好的收敛和学习，mAP@0.5值均超过0.8。
\begin{figure}[H]
    \centering
    \includegraphics[width=0.87\textwidth]{YOLOv5/train_yolov5/PR_curve.png}
    \caption{YOLOv5的准确度-召回率图，YOLOv8与之类似。}
    \label{fig:3}
\end{figure}

如图4，对YOLOv5的归一化混淆矩阵的分析中，我们发现公交车标识、慢行标识、自行车道三种标识，网络都能百分百准确地识别出。这也是由于这些标识本身就含有文字或含有的信息较多。而对于车道线这样的图形信息较少的标识，如图中的Liniya1与Liniya2，网络还未能做到非常好的识别。综合来看，如图5中的mAP50-95，可以看到YOLOv8在精确性能上优于YOLOv5。
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{YOLOv5/train_yolov5/confusion_matrix_normalized.png}
    \caption{YOLOv5的归一化混淆矩阵图，YOLOv8与之类似。}
    \label{fig:4}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.82\textwidth]{contrast.png}
    \caption{YOLOv5与YOLOv8的mAP对比。YOLOv8略优与YOLOv5。}
    \label{fig:5}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{总结与展望}
本文对比了经典的机器学习方法HOG+SVM，与YOLOv5和YOLOv8在现实环境下的路标识别能力。设计了一个针对现实场景的算法对比实现，结果看出HOG+SVM算法虽然不需要强大的算力进行训练，但实际效果也较差，无法投入实际运用。YOLO网络在测试中表现出了强大的能力，但是对应的也需要一定时间用于训练。关于YOLOv5和YOLOv8，在精准率和召回率这两项指标上两者各有千秋，但在mAP指标上YOLOv8一致保持优于YOLOv5。YOLOv8在精确性能上优于YOLOv5，而YOLOv5因在网络参数的优势，训练速度上是优于YOLOv8，因此在实际应用中，要综合考量精准性能和部署速度，从而选择最适合的算法。

对于在这一方向上的一些未来展望，近来的一些工作基于改善网络结构，对类似路标的小目标检测做了特殊优化。虽然在mAP指标上做到了一定提升，但是这些工作并没有提高识别的准确率。并且这一些工作都基于较老的YOLO网络，并没有在最新的YOLOv8网络基础上进行优化，因此也无法进行合适的比较。未来可以借鉴类似的一些优化经验，并迁移到YOLOv8或更新的最优网络基础上进行优化，进一步提高性能。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{学习体会和建议}
本学期在模式识别课上，方昱春老师深入地介绍了一些模式识别的理论基础，与不同算法模型和技术，以及它们在一些不同场景中的应用。建立起一定的理论基础后，通过研讨和小组作业等形式，上手实际项目，让我更好地理解了算法模型的工作原理、优缺点以及如何调整参数以提高性能。这培养了我解决问题的能力，从而选择合适的方法，并在实践中更加灵活地应用知识。希望今后能在课程中加入更多前沿领域的最新科研成果分享，并与小组作业有机结合起来，让同学们更好地感受到新成果带来的进步，并能有机会启发同学们在今后参与进前沿的计算机科研的的工作中去的热情。


%%%%%%%%%%%%%%%%%%%引用文献%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{article}      % 指定article 代表同目录下的article.bib文件 
\bibliographystyle{ieeetr}  % 定义文献引用的格式

%%%%%%%%%%%%%%%%%%%%%%%附录%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage{}
\appendix
\section{附录}
\begin{appendices}
    核心代码节选：
    \lstset{language=Python}
    \begin{lstlisting}
# HOG + SVM
from skimage import feature as ft 
import cv2
def hog_feature(img_array, resize=(64,64)):
    """extract hog feature from an image."""
    img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
    img = cv2.resize(img, resize)
    bins = 9
    cell_size = (8, 8)
    cpb = (2, 2)
    norm = "L2"
    features = ft.hog(img,
                      orientations=bins,
                      pixels_per_cell=cell_size, 
                      cells_per_block=cpb,
                      block_norm=norm,
                      transform_sqrt=True)
    return features

# YOLO training
from wandb.integration.ultralytics import add_wandb_callback
import wandb
from ultralytics import YOLO

wandb.init(project="YOLOv5")
model = YOLO("./yolov5nu.pt") # ./yolov8n.pt
add_wandb_callback(model, enable_model_checkpointing=True)
results = model.train(project="YOLOv5",
                      data="./datasets/data.yaml",
                      epochs=100,
                      save_period=10,
                      seed=42)
model_best = YOLO("./YOLOv5/train/weights/best.pt")
metrics = model_best.val()
wandb.finish()

# Calculate PR and F1
for img_name, obj_label in label_dict.items():
    obj_predict = predict_dict[img_name]
    for obj, coords in obj_predict.items():
        img_num_predict[obj] += len(coords)
    for obj, coords in obj_label.items():
        img_num_per_cls[obj] += len(coords)
        if obj in obj_predict.keys():
            for coord1 in coords:
                for coord2 in obj_predict[obj]:
                    if compute_iou(coord1, coord2)>=iou1:
                        tp_count[obj] +=1
for cls_name in cls_names:
    p = tp_count[cls_name]/img_num_predict[cls_name]
    r = tp_count[cls_name]/img_num_per_cls[cls_name]
    f1 = 2*p*r/(p+r)
    pre_rec[cls_name] = [p, r, f1]
return pre_rec

# PR curve drawing
def plot_pr_curve(px, py, ap,
                  save_dir=Path("pr_curve.png"),
                  names=()):
    """Plots a precision-recall curve."""
    fig, ax = plt.subplots(1, 1, figsize=(9, 6))
    py = np.stack(py, axis=1)

    for i, y in enumerate(py.T):
        ax.plot(px, y, linewidth=1,
                label=f"{names[i]} {ap[i, 0]:.3f}")

    ax.plot(px, py.mean(1), linewidth=3, color="blue",
            label="all classes %.3f mAP@0.5"%ap[:, 0].mean())
    ax.set_xlabel("Recall")
    ax.set_ylabel("Precision")
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.legend(bbox_to_anchor=(1.04, 1), loc="upper left")
    ax.set_title("Precision-Recall Curve")
    fig.savefig(save_dir, dpi=250)
    plt.close(fig)

    \end{lstlisting}
\end{appendices}

\end{document}
